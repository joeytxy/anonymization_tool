{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad978fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from operator import itemgetter\n",
    "from itertools import groupby\n",
    "import re\n",
    "import nltk\n",
    "from nltk import word_tokenize,pos_tag\n",
    "import spacy\n",
    "import en_core_web_sm\n",
    "spacy_nlp = en_core_web_sm.load()\n",
    "from flair.data import Sentence\n",
    "from flair.models import SequenceTagger\n",
    "from flair.tokenization import SpacyTokenizer\n",
    "tagger=SequenceTagger.load('ner')\n",
    "import stanza\n",
    "stanza_nlp = stanza.Pipeline('en', download_method=None)\n",
    "\n",
    "def anonymized_text_color(user_input,package=['stanza'],union_intersection=None,additional_details=None,additional_expression=None):\n",
    "    if len(package)==1 and union_intersection!=None:\n",
    "        raise Exception(\"Unable to combine less than 2 packages\")\n",
    "    elif len(package)>1 and union_intersection==None:\n",
    "        raise Exception(\"Please state if you would like to intersect or union the packages you have stated\")\n",
    "    else:\n",
    "\n",
    "        colored_text=user_input\n",
    "        final_return=user_input\n",
    "        \n",
    "        # to obtain full list of index for eg [0,8]->[0,1,2,3,4,5,6,7,8]\n",
    "        def index_list(list1):   \n",
    "            final_list=[]\n",
    "            for i in list1:\n",
    "                for j in range(i[0],i[1]+1):\n",
    "                    final_list.append(j)\n",
    "            return final_list\n",
    "\n",
    "        #to obtain range for each set of consecutive numbers after union/intersection for eg [0,1,2,3,4,5] -> [0,5]\n",
    "        def range_lists(list1):   \n",
    "            output=[]\n",
    "            for k, g in groupby(enumerate(list1), lambda x: x[0]-x[1]):\n",
    "                group=list(map(itemgetter(1), g))\n",
    "                output.append([group[0],group[-1]])\n",
    "            return output\n",
    "\n",
    "        #to obtain identified names for eg user_input[0:5]\n",
    "        def name_list(list1): \n",
    "            final_names=[]\n",
    "            for i in list1:\n",
    "                final_names.append(user_input[i[0]:i[1]])\n",
    "            final_names=sorted(final_names,key=len,reverse=True)\n",
    "            return final_names\n",
    "    \n",
    "\n",
    "        accumulated=[]\n",
    "        \n",
    "        if 'nltk' in package:\n",
    "            \n",
    "            df=pd.DataFrame()\n",
    "            \n",
    "            #obtain word and corresponding tag\n",
    "            for chunk in nltk.ne_chunk(nltk.pos_tag(nltk.word_tokenize(user_input))):\n",
    "                if hasattr(chunk,'label'):\n",
    "                    for c in chunk:\n",
    "                        data={'word':[c[0]],'label':[chunk.label()]}\n",
    "                        tmp = pd.DataFrame(data)\n",
    "                        df=pd.concat([df,tmp])\n",
    "            \n",
    "                else:\n",
    "                    data={'word':[chunk[0]],'label':[chunk[1]]}\n",
    "                    tmp = pd.DataFrame(data)\n",
    "                    df=pd.concat([df,tmp])\n",
    "            counter=0\n",
    "            list_of_indices=[]\n",
    "\n",
    "            #search for word's start index to end index in user_input\n",
    "            for i in df['word']:\n",
    "                while counter<len(user_input):\n",
    "                    if i==user_input[counter:counter+len(i)]:\n",
    "                        list_of_indices.append([counter,counter+len(i)])\n",
    "                        counter=counter+len(i)\n",
    "                        break\n",
    "                    else:\n",
    "                        counter=counter+1\n",
    "            df['index']=list_of_indices\n",
    "\n",
    "            #to obtain person name \n",
    "            df=df[df['label']==\"PERSON\"] #obtain a df (example row: Anna  PERSON  [0,4])\n",
    "            nltk_index_list=[]\n",
    "\n",
    "            #append each range (start char index, end char index) of name to list\n",
    "            #combine if the words are consecutive (to eliminate problem of identifying first name and last name as two names)\n",
    "            for i in df['index']:\n",
    "                if len(nltk_index_list)>0 and i[0]==nltk_index_list[-1][1]+1:\n",
    "                    nltk_index_list[-1][1]=i[1]\n",
    "                else:\n",
    "                    nltk_index_list.append(i)\n",
    "\n",
    "            #if user chooses to just use nltk to anonymize text then use each range directly\n",
    "            if len(package)==1:\n",
    "                accumulated.append(nltk_index_list)\n",
    "\n",
    "            #if need to union/intersect, obtain full list of character index      \n",
    "            else:\n",
    "                nltk_index=index_list(nltk_index_list)\n",
    "                accumulated.append(nltk_index)\n",
    "            \n",
    "        if 'spacy' in package:\n",
    "            spacy_doc = spacy_nlp(user_input)\n",
    "            spacy_index_list=[]\n",
    "            #append range (start char index,end char index) of person name identified to list\n",
    "            for ent in spacy_doc.ents:\n",
    "                if ent.label_==\"PERSON\":\n",
    "                    if len(spacy_index_list)>0 and ent.start_char==spacy_index_list[-1][1]+1:\n",
    "                        spacy_index_list[-1][1]=ent.end_char\n",
    "                    else:\n",
    "                        spacy_index_list.append([ent.start_char,ent.end_char])\n",
    "\n",
    "            #if user chooses to just use spacy to anonymize text then use each range directly \n",
    "            if len(package)==1:\n",
    "                accumulated.append(spacy_index_list)\n",
    "\n",
    "            #if need to union/intersect, obtain full list of character index\n",
    "            else:\n",
    "                spacy_index=index_list(spacy_index_list)\n",
    "                accumulated.append(spacy_index)\n",
    "            \n",
    "        if 'flair' in package:\n",
    "            text=Sentence(user_input,use_tokenizer=SpacyTokenizer(spacy_nlp))\n",
    "            tagger.predict(text)\n",
    "            flair_index_list=[]\n",
    "            #append range (start char index,end char index) of person name identified to list\n",
    "            for entity in text.get_spans('ner'):\n",
    "                if entity.get_label('ner').value==\"PER\":\n",
    "                    if len(flair_index_list)>0 and entity.start_position==flair_index_list[-1][1]+1:\n",
    "                        flair_index_list[-1][1]=entity.end_position\n",
    "                    else:\n",
    "                        flair_index_list.append([entity.start_position,entity.end_position])\n",
    "\n",
    "            #if user chooses to just use flair to anonymize text then use each range directly \n",
    "            if len(package)==1:\n",
    "                accumulated.append(flair_index_list)\n",
    "\n",
    "            #if need to union/intersect, obtain full list of character index\n",
    "            else:\n",
    "                flair_index=index_list(flair_index_list)\n",
    "                accumulated.append(flair_index)\n",
    "            \n",
    "        if 'stanza' in package:\n",
    "            stanza_doc=stanza_nlp(user_input)\n",
    "            tag_list=[]\n",
    "            stanza_name_list=[]\n",
    "            #append range (start char index,end char index) of person name identified to list\n",
    "            for i in range(0,len(stanza_doc.sentences)):\n",
    "                stanza_index_list=[]\n",
    "                for entity in stanza_doc.entities:\n",
    "                    if entity.type==\"PERSON\":\n",
    "                        if len(stanza_index_list)>0 and entity.start_char==stanza_index_list[-1][1]+1:\n",
    "                            stanza_index_list[-1][1]=entity.end_char\n",
    "                        else:\n",
    "                            stanza_index_list.append([entity.start_char,entity.end_char])\n",
    "\n",
    "            #if user chooses to just use stanza to anonymize text then use each range directly \n",
    "            if len(package)==1:\n",
    "                accumulated.append(stanza_index_list)\n",
    "\n",
    "            #if need to union/intersect, obtain full list of character index\n",
    "            else:\n",
    "                stanza_index=index_list(stanza_index_list)\n",
    "                accumulated.append(stanza_index)\n",
    "\n",
    "        if union_intersection!=None and union_intersection.lower()=='union':\n",
    "            #obtain union of lists given by relevant packages\n",
    "            def union(list1):\n",
    "                return list(set().union(*list1))\n",
    "            \n",
    "            #sort list to check for consecutive numbers\n",
    "            sorted_list=union(accumulated)\n",
    "            sorted_list.sort()\n",
    "            union_list=range_lists(sorted_list)\n",
    "            \n",
    "            #obtain name list\n",
    "            name_to_mask=name_list(union_list)\n",
    "            \n",
    "        elif union_intersection!=None and union_intersection.lower()=='intersection':\n",
    "            #obtain intersection of lists given by relevant packages\n",
    "            def intersect(list1):\n",
    "                return list(set.intersection(*map(set, list1)))\n",
    "\n",
    "            #sort list to check for consecutive numbers\n",
    "            sorted_list=intersect(accumulated)\n",
    "            sorted_list.sort()\n",
    "            intersection_list=range_lists(sorted_list)\n",
    "\n",
    "            #obtain name list\n",
    "            name_to_mask=name_list(intersection_list)\n",
    "        else:   #case where only one package is used\n",
    "            if len(accumulated[0])!=0:\n",
    "                name_to_mask=name_list(accumulated[0])\n",
    "            else:\n",
    "                #case where no personal names were identified \n",
    "                name_to_mask=[]\n",
    "\n",
    "        #sort name list to ensure full name is masked first before masking instances where only first name is used \n",
    "        name_to_mask=sorted(name_to_mask, key=len,reverse=True)\n",
    "        for i in name_to_mask:\n",
    "            colored_text=colored_text.replace(i,''.join([\"\\033[0;31m\",i,\"\\033[0;0m\"]))\n",
    "            final_return=final_return.replace(i,\"[Name]\")\n",
    "            final_return=final_return.replace(\"[Name]\",\"\\033[0;31m[Name]\\033[0;0m\")\n",
    "            \n",
    "        #this is for cases where part of this name is tagged as name by the package\n",
    "        #to ensure that the full name is colored\n",
    "        for i in re.findall(r\"(\\033[0[;]+0m.\\D+\\033[0[;]+0m)\",colored_text):\n",
    "            colored_text=colored_text.replace(i,''.join([\"\\033[0;31m\",i[6:]]))\n",
    "        colored_text=colored_text.replace(\"\\033[0;31m \\033[0;31m\",\"\\033[0;31m\")\n",
    "        \n",
    "        #mask additional details if requested     \n",
    "        if additional_details!=None: \n",
    "            if 1 in additional_details:\n",
    "                for i in re.findall(r\"([sftg]\\d{7}[a-z])\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;32m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"([sftg]\\d{7}[a-z])\", \"[NRIC]\", final_return,flags=re.IGNORECASE) \n",
    "                final_return=final_return.replace(\"[NRIC]\",\"\\033[0;32m[NRIC]\\033[0;0m\")\n",
    "            if 2 in additional_details:\n",
    "                for i in re.findall(r\"(\\d{10}[A-z])\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;33m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(\\d{10}[A-z])\", \"[CASENO]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"[CASENO]\",\"\\033[0;33m[CASENO]\\033[0;0m\")\n",
    "            if 3 in additional_details:\n",
    "                for i in re.findall(r\"(\\d{8})\",final_return):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;34m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(\\d{8})\", \"[PHONE]\", final_return)\n",
    "                final_return=final_return.replace(\"[PHONE]\",\"\\033[0;34m[PHONE]\\033[0;0m\")\n",
    "            if 4 in additional_details:\n",
    "                for i in re.findall(r\"([a-z]\\d{4}[a-z])\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;35m\",i,\"\\033[0;0m\"]))\n",
    "                for i in re.findall(r\"(\\d{5}[a-z])\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;35m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"([a-z]\\d{4}[a-z])\", \"[ID]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return = re.sub(r\"(\\d{5}[a-z])\", \"[ID]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"[ID]\",\"\\033[0;35m[ID]\\033[0;0m\")\n",
    "            if 5 in additional_details:\n",
    "                for i in re.findall(r\"(\\d{1,2}.\\d{1,2}.\\d{2,4})\",final_return):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;36m\",i,\"\\033[0;0m\"]))\n",
    "                for i in re.findall(r\"(\\d{1,2}.(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?).\\d{2,4})\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;36m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(\\d{1,2}.\\d{1,2}.\\d{2,4})\", \"[DATE]\", final_return)\n",
    "                final_return = re.sub(r\"(\\d{1,2}.(?:Jan(?:uary)?|Feb(?:ruary)?|Mar(?:ch)?|Apr(?:il)?|May|Jun(?:e)?|Jul(?:y)?|Aug(?:ust)?|Sep(?:tember)?|Oct(?:ober)?|Nov(?:ember)?|Dec(?:ember)?).\\d{2,4})\", \"[DATE]\",final_return,flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"[DATE]\",\"\\033[0;36m[DATE]\\033[0;0m\")\n",
    "            if 6 in additional_details:\n",
    "                for i in re.findall(r\"(admission Time.\\s\\d+.\\d+)\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;91m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(admission Time.\\s\\d+.\\d+)\", \"Admission Time: [Time]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"Admission Time: [Time]\",\"\\033[0;91mAdmission Time: [Time]\\033[0;0m\")\n",
    "            if 7 in additional_details:\n",
    "                for i in re.findall(r\"(ward.\\w+\\s[a-zA-z0-9]+)\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;93m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(ward.\\w+\\s[a-zA-z0-9]+)\", \"Ward:[WardNo]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"Ward:[WardNo]\",\"\\033[0;93mWard:[WardNo]\\033[0;0m\")\n",
    "            if 8 in additional_details:\n",
    "                for i in re.findall(r\"(bed.\\s[a-z0-9]+)\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;95m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(bed.\\s[a-z0-9]+)\", \"Bed:[BedNo]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"Bed:[BedNo]\",\"\\033[0;95mBed:[BedNo]\\033[0;0m\")\n",
    "            if 9 in additional_details:\n",
    "                for i in re.findall(r\"(patient class.\\s\\w+\\s[A-Z])\",final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(i,''.join([\"\\033[0;96m\",i,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(r\"(patient class.\\s\\w+\\s[A-Z])\", \"Patient Class:[Class]\", final_return, flags=re.IGNORECASE)\n",
    "                final_return=final_return.replace(\"Patient Class:[Class]\",\"\\033[0;96mPatient Class:[Class]\\033[0;0m\")\n",
    "        if additional_expression!=None:\n",
    "            for i in additional_expression:\n",
    "                for j in re.findall(i[0],final_return,flags=re.IGNORECASE):\n",
    "                    colored_text=colored_text.replace(j,''.join([\"\\033[4;30m\",j,\"\\033[0;0m\"]))\n",
    "                final_return = re.sub(i[0],i[1],final_return,flags=re.IGNORECASE)\n",
    "                final_return = final_return.replace(i[1],''.join([\"\\033[4;30m\",i[1],\"\\033[0;0m\"]))\n",
    "        print(colored_text)\n",
    "        print(\"\\n\")\n",
    "        print(final_return)\n",
    "              \n",
    "def anonymized_file_input_color(user_input,package=['stanza'],union_intersection=None,additional_details=None,additional_expression=None):\n",
    "    if len(package)==1 and union_intersection!=None:\n",
    "        raise Exception(\"Unable to combine less than 2 packages\")\n",
    "    elif len(package)>1 and union_intersection==None:\n",
    "        raise Exception(\"Please state if you would like to intersect or union the packages you have stated\")\n",
    "    else:\n",
    "\n",
    "        #for txt file    \n",
    "        if user_input.endswith(\".txt\"):\n",
    "            with open(user_input) as f:\n",
    "                text=\"\"\n",
    "                lines = f.readlines()\n",
    "                for line in lines:\n",
    "                    text+=line\n",
    "                anonymized_text_color(text,package=package,union_intersection=union_intersection,additional_details=additional_details,additional_expression=additional_expression)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
